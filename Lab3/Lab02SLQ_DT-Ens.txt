Lab02: Decision trees and Ensemble learning
============================================

Les étudiants doivent compléter le code afin de créer deux classifieurs : ID3 et CART.
Le premier pour les caractéristiques nominales et le deuxième pour celles numériques.
Dans la deuxième partie, une série des tests sur les arbres de décision (CART) 
et les forêts aléatoires est appliuée, en modifiant certains paramètres. 
Les étudiants doivent lier les résultats de ces tests avec ce qu'il ont vu dans le cours. 


TOOLS:
------
Python, Jupyter, pandas, scikit-learn, numpy, timeit, graphviz

DATASETS:
---------
Cars Data

PLAN:
-----
I. Algorithms implementation
    I.1. ID3
    I.2. CART
II. Application and Analsis
    II.1. Decision trees and Random forests
    II.2. Ensemle Learning
  
WHAT TO DO:
-----------
I- Algorithms implementation
    - Probability of a value given a set         [4pts]
    - Entropy                                    [4pts]
    - Information gain                           [4pts]
    - ID3 splitting feature selection            [4pts]
    - ID3 Stopping Criterion                     [4pts]
    - Gini impurity                              [4pts]
    - Gini impurity for the split                [4pts]
    - CART splitting feature and value selection [4pts]
    
II- Application and Analsis
    - Feature selection criteria                 [6pts = 2 + 2 + 2]
    - Maximum depth                              [8pts = 2 + 2 + 2 + 2]
    - Minimum leaf samples                       [4pts = 2 + 2]
    - Estimators' number (Ensemble)              [8pts = 2 + 2 + 2 + 2]
    - Bootstrap's size                           [6pts = 2 + 2 + 2]
    
Progress in class                                [8pts]
Submit the lab on time                           [8pts]
